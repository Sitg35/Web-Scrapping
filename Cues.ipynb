{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from concurrent.futures import ProcessPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(url):\n",
    "    \n",
    "    r = requests.get(url)\n",
    "                            \n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color_inside(soup):\n",
    "    \n",
    "    color = soup.find(\"div\",{\"style\":\"width: 30%\"}).select(\"li\")[1].text\n",
    "    \n",
    "    return color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worker-0: looking for the next url\n",
      "MainThread: queuing {}http://google.com\n",
      "MainThread: queuing {}http://marca.com\n",
      "MainThread: queuing {}http://sitgesmaq.com\n",
      "MainThread: *** main thread waiting\n",
      "worker-0: downloading http://google.com\n",
      "worker-0: looking for the next url\n",
      "worker-0: downloading http://marca.com\n",
      "worker-0: looking for the next url\n",
      "worker-0: downloading http://sitgesmaq.com\n",
      "worker-0: looking for the next urlMainThread: *** done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from queue import Queue\n",
    "import threading\n",
    "from time import sleep\n",
    "import urllib\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "\n",
    "# Set up some global variables\n",
    "num_fetch_threads = 1\n",
    "processing_queue = Queue()\n",
    "\n",
    "def message(s):\n",
    "    print('{}: {}'.format(threading.current_thread().name, s))\n",
    "    \n",
    "def download_enclosures(q, results):\n",
    "    \"\"\"This is the worker thread function.\n",
    "    It processes items in the queue one after\n",
    "    another.  These daemon threads go into an\n",
    "    infinite loop, and exit only when\n",
    "    the main thread ends.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        message('looking for the next url')\n",
    "        url = q.get()\n",
    "        message('processing {}'.format(url))\n",
    "        # TODO: Afegir codi de la funció aquí\n",
    "         color = get_color_inside(parsed_url)\n",
    "        # results.append(result)\n",
    "        q.task_done()\n",
    "       \n",
    "\n",
    "# Set up some threads to fetch the enclosures\n",
    "for i in range(num_fetch_threads):\n",
    "    worker = threading.Thread(\n",
    "        target=download_enclosures,\n",
    "        args=(processing_queue,results),\n",
    "        name='worker-{}'.format(i),\n",
    "    )\n",
    "    worker.setDaemon(True)\n",
    "    worker.start()\n",
    "    \n",
    "# Obtenir llista de urls\n",
    "start_url = 'https://motos.coches.net/ocasion/default.aspx?pg=1&MakeId=69&FuelTypeId=2&BodyTypeId=10&or=-1&fi=SortDate'\n",
    "next_url = start_url\n",
    "while next_url != 0:\n",
    "    parsed_url = get_url(next_url)\n",
    "    for name in parsed_url.find_all(\"div\",{\"style\":\"position:relative\"}):\n",
    "        inside_url = 'https://motos.coches.net' + name.select('a')[0]['href']\n",
    "        message('queuing: ' + inside_url)\n",
    "        processing_queue.put(inside_url)\n",
    "\n",
    "    try:\n",
    "        next_url = 'https://motos.coches.net/ocasion/default.aspx' + parsed_url.find(\"a\",{\"class\":\"pnext\"}).get(\"href\") \n",
    "    except:\n",
    "        next_url = 0\n",
    "            \n",
    "# Now wait for the queue to be empty, indicating that we have\n",
    "# processed all of the downloads.\n",
    "message('*** main thread waiting')\n",
    "processing_queue.join()\n",
    "message('*** done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
